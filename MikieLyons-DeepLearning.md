**Deep Learning**

Mikie Lyons


Deep learning (also known as deep structured learning or hierarchical learning) is part of a broader family of machine learning methods
based on learning data representations, as opposed to task-specific algorithms. Learning can be supervised, semi-supervised or
unsupervised.
Deep learning models are loosely related to information processing and communication patterns in a biological nervous system, such as
neural coding that attempts to define a relationship between various stimuli and associated neuronal responses in the brain.
Deep learning architectures such as deep neural networks, deep belief networks and recurrent neural networks have been applied to fields
including computer vision, speech recognition, natural language processing, audio recognition, social network filtering, machine
translation, bioinformatics and drug design, where they have produced results comparable to and in some cases superior to human experts.

https://en.wikipedia.org/wiki/Deep_learning#/media/File:Kernel_Machine.svg

* History
The term Deep Learning was introduced to the machine learning community by Rina Dechter in 1986, and to Artificial Neural Networks by
Igor Aizenberg and colleagues in 2000, in the context of Boolean threshold neurons.
The first general, working learning algorithm for supervised, deep, feedforward, multilayer perceptrons was published by Alexey
Ivakhnenko and Lapa in 1965. A 1971 paper described a deep network with 8 layers trained by the group method of data handling algorithm.
Deep learning is part of state-of-the-art systems in various disciplines, particularly computer vision and automatic speech recognition
(ASR). Results on commonly used evaluation sets such as TIMIT (ASR) and MNIST (image classification), as well as a range of
large-vocabulary speech recognition tasks have steadily improved. Convolutional neural networks (CNNs) were superseded for ASR by CTC 
for LSTM, but are more successful in computer vision.
The impact of deep learning in industry began in the early 2000s, when CNNs already processed an estimated 10% to 20% of all the checks
written in the US, according to Yann LeCun. Industrial applications of deep learning to large-scale speech recognition started around
2010.
In 2012, a team led by Dahl won the "Merck Molecular Activity Challenge" using multi-task deep neural networks to predict the
biomolecular target of one drug. In 2014, Hochreiter's group used deep learning to detect off-target and toxic effects of
environmental chemicals in nutrients, household products and drugs and won the "Tox21 Data Challenge" of NIH, FDA and NCATS.



Deep learning is a class of machine learning algorithms that:
* Use a cascade of multiple layers of nonlinear processing units for feature extraction and transformation. Each successive layer uses
the output from the previous layer as input.
* Learn in supervised (e.g., classification) and/or unsupervised (e.g., pattern analysis) manners.
* Learn multiple levels of representations that correspond to different levels of abstraction; the levels form a hierarchy of concepts.

























