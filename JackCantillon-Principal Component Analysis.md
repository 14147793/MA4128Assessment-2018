## Principal Component Analysis

#### What is Principal Component Analysis

Principal components analysis (PCA) is a data reduction technique that lowers the dimensionality of data while retaining almost all of the variance in the data set. By creating a new coordinate system using principal components (PC), PCA manages to reduce the dimensionality of the data along with which the variation in the data is maximal. When using a select number of components, every sample can be presented using a relatively small number of values in contrast to having values for a large number of variables. This makes it easy to plot samples which in turn allows diﬀerences and similarities between these samples to be easily identiﬁable and makes the process of potentially grouping samples much more straight forward. PCA establishes new variables, the principal components, that are linear combinations of the initial variables.

The value of PCA become clear when we are dealing with very large data sets, such as spectroscopic (an optical device for producing and observing a spectrum of light or radiation from a source) data. In the case of near infrared (NIR data). It takes measurements every 2 nm (nanometer) over the range 1100-2498 nm. As a result over 700 variables are recorded, but the ﬁrst 20 PC’s will contain the vast majority of the information. The processes of ﬁnding PCs is quite straight forward. The ﬁrst PC is determined by ﬁnding the direction through the data that explains most of the variability in the data. The second, and ensuing, PCs have to be orthogonal (intersecting at right angles) to the previous PC and illustrate the maximum amount of variation that is remaining. When the directions of the PCs are known, geometrical knowledge enables expression of the values of the individual samples in terms of PCs as linear summations of the initial data multiplied by a coeﬃcient which describes the PC. The new values that we have calculated are called scores and every sample will have it own unique score for each PC. Because there is no notion of the output in PCA it is an unsupervised learning method.

#### Why is Principal Component Analysis
PCA is mostly used as a tool in exploratory data analysis and for making predictive models. It's often used to visualize genetic distance and relatedness between populations. PCA can be done by eigenvalue decomposition of a data covariance (or correlation) matrix or singular value decomposition of a data matrix, usually after mean centering (and normalizing or using Z-scores) the data matrix for each attribute. The results of a PCA are usually discussed in terms of component scores, sometimes called factor scores (the transformed variable values corresponding to a particular data point), and loadings (the weight by which each standardized original variable should be multiplied to get the component score).

#### Quantitative Finance
In quantitative finance, principal component analysis can be directly applied to the risk management of interest rate derivatives portfolios. Trading multiple swap instruments which are usually a function of 30-500 other market quotable swap instruments is sought to be reduced to usually 3 or 4 principal components, representing the path of interest rates on a macro basis. Converting risks to be represented as those to factor loadings (or multipliers) provides assessments and understanding beyond that available to simply collectively viewing risks to individual 30-500 buckets. PCA has also been applied to share portfolios in a similar fashion. One application is to reduce portfolio risk, where allocation strategies are applied to the "principal portfolios" instead of the underlying stocks. A second is to enhance portfolio return, using the principal components to select stocks with upside potential.
