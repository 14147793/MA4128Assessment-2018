## Apache Spark
Jack Cantillon 14146746

Apache Spark is an open-source cluster-computing framework. It was created in the AMPLab at the University of California in Berkeley. The AMPLabis a lab that specialises in the analytics of Big Data. Apache Spark enables an interface that allows wntire clusters to be programmed with data parallelism and fault tolerance.

Resilient distributed dataset (RDD) is the basis of Apache Spark. RDD is a read only set of data objects spread over a cluster of machines. Spark and RDD were created in 2012 in reaction to the deficiencies in the MapReduce clustering computer paradigm. Spark allows the application of iterative algorithms, visits data sets numerous times via a loop, and iterative/ exploratory data analysis. The latency (time interval between the simulation and response) of such functions can be decresed by several orders of magnitude in comtrast to MapReduce implementation.
